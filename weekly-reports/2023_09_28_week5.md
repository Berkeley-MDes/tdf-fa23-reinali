# Week 5 Progress Report- -09/28/2023

## Reina Li

### Reflection
#### Photon 2 set up continue and testint out different scenerios
In our first class, we focused on setting up our Photon 2 devices and connecting it to the internet. The process of connecting to the internet was quick and straightforward. You can see that my device is in good condition in the picture, as it emits a dim blue light.:+1:
 <img src="https://github.com/Berkeley-MDes/tdf-fa23-reinali/blob/main/weekly-reports/605879365804014490.jpg" alt="Alt Text" width="200">

Afterward, we kept going with the exercise of placing the controller on the breadboard. I followed along with the professor's guidance, first putting the wires in position, then inserting the light, and finally, plugging in the microcontroller into my computer. The fiinal light dimmed up, and I thought it was quite easy to follow along because the instructions were clear.
<img src="https://github.com/Berkeley-MDes/tdf-fa23-reinali/blob/main/weekly-reports/166338030270120533.jpg" alt="Alt Text" width="500">

Next, we connected more wires and added a sensor to the breadboard. What surprised me was that the lights turned off. I initially thought I had made a mistake, so I kept checking the code and the alignment of my wires, which were indeed correct. Then, I asked the professir and discovered that when I touched the sensor, the number on the debug code decreased, which was the intended outcome. The light wasn't supposed to turn on; instead, the circuit was designed for the sensor to trigger a change. which is the sucess of this exercise.:+1:
<img src="https://github.com/Berkeley-MDes/tdf-fa23-reinali/blob/main/weekly-reports/423903021796022641.jpg" alt="Alt Text" width="300">

#### Braintorming for photon 2 ideations
My assigned group was focusing on education, and we began by individually brainstorming ideas for about 3 minutes before talking with each other and share out our ideas. Each of us contributed to a list of problems that we believed were relevant to address. Examples included gamification, time management, media influences, teaching communication with pets, and overcoming language barriers. It was fascinating to see the diverse approaches people took. I primarily thought off academic-related issues, while one of my classmates came up with the idea of facilitating communication with pets, which I found really intriguing. 
From all the proposed topics, we selected the top three: media influence, communication with pets, and teaching programming to children. We then specified the target age groups and documented the results in an Excel sheet, which can be viewed [here](https://docs.google.com/spreadsheets/d/1CpsCjrJQfYHX2UK_Z-hcCsMAT5qSUTG1D3hT1wNzCT0/edit#gid=0)

I looked through all the ideas and thought they were very interesting. I really want to focus on more interactive and immersive ideas while having an idea that is quite relevant these days so I narrowed down my three choices as. 

1. Mindful Meditations: An Interactive Flower Guide for Stress Relief and Color Therapy Tracking
2. Exploring Mental Health Needs of Graduate Students: Building Physical Sensors for Anxiety Tracking and Study Habits Analysis
3. Exploring AI-Enabled Pet Wearables for Training and Communication

### Speculation
#### Future Direction of the tool
I believe the microcontroller could be effectively integrated with AI. Going back on the sensor exercise with the breadboard, I realized that sensor integration could be combined with AI to detect human heartbeats, brainwaves, or even body temperature for the future of wearable technology, I thought this is something quite cool and another step into the market. This integration might also contribute to the prevention of equipment failures and improve efficiency, as the system might detect certain errors more frequently. Furthermore, I think it could be incorporated into face or speech recognition to tailor the device to the specific needs of users.

#### Future Direction my work
As of right now, Photon 2 seems to hold less storage data than computer chips. Perhaps this could be a direction for improvement, allowing it to handle more complex tasks and larger-scale projects. I think it could be a cool design feature to incorporate multi-sensory capabilities, targeting two or more senses to accomplish specific design tasks, it is definitely another avenue to explore. Furthermore, microcontrollers can also be integrated with artificial intelligence, potentially improving character recognition and achieving more accurate characterization of humans and text.

